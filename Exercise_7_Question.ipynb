{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "6aec4757-3da7-4f16-91cd-ba8b071894f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None) # Your Code Here\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  # Your Code Here\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-29 08:58:18--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.76.128, 2a00:1450:400c:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.76.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   123MB/s    in 0.7s    \n",
            "\n",
            "2019-06-29 08:58:19 (123 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0629 08:58:20.147506 140234293569408 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "336f9c4d-865f-47d3-f3ca-43ae03e3aa01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "44775bf4-1aa1-45e6-e795-66034573bc87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation = 'relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation = 'sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0629 09:04:53.651993 140234293569408 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "7135bd5c-cfbf-4677-a184-67e4052a19f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-29 09:05:28--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.76.128, 2a00:1450:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.76.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  49.1MB/s    in 2.9s    \n",
            "\n",
            "2019-06-29 09:05:31 (49.1 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-06-29 09:05:32--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.167.128, 2a00:1450:400c:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.167.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  63.3MB/s    in 0.2s    \n",
            "\n",
            "2019-06-29 09:05:33 (63.3 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "d75746a4-6c00-42ad-96eb-4058dee4e4f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "7bb72cff-9afd-4e7f-984f-556a4af91f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "#train_dir = '/tmp/training'\n",
        "#validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.,\n",
        "                                  rotation_range = 40,\n",
        "                                  width_shift_range = 0.2,\n",
        "                                  height_shift_range = 0.2,\n",
        "                                  shear_range = 0.2,\n",
        "                                  zoom_range = 0.2,\n",
        "                                  horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                   batch_size = 20,\n",
        "                                                   class_mode = 'binary',\n",
        "                                                   target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                   batch_size = 20,\n",
        "                                                   class_mode = 'binary',\n",
        "                                                   target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "b022fe79-380e-4240-bd61-c2d71967f092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback() # Your Code Here\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 35s - loss: 0.2023 - acc: 0.9179 - val_loss: 0.0020 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "100/100 - 30s - loss: 0.0498 - acc: 0.9807 - val_loss: 0.0160 - val_acc: 0.9879\n",
            "Epoch 3/100\n",
            "100/100 - 29s - loss: 0.0435 - acc: 0.9792 - val_loss: 0.1264 - val_acc: 0.9717\n",
            "Epoch 4/100\n",
            "100/100 - 30s - loss: 0.0341 - acc: 0.9848 - val_loss: 0.0350 - val_acc: 0.9929\n",
            "Epoch 5/100\n",
            "100/100 - 29s - loss: 0.0355 - acc: 0.9904 - val_loss: 8.8051e-04 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "100/100 - 29s - loss: 0.0492 - acc: 0.9859 - val_loss: 0.2638 - val_acc: 0.9555\n",
            "Epoch 7/100\n",
            "100/100 - 29s - loss: 0.0223 - acc: 0.9913 - val_loss: 0.0796 - val_acc: 0.9808\n",
            "Epoch 8/100\n",
            "100/100 - 29s - loss: 0.0246 - acc: 0.9914 - val_loss: 0.0026 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "100/100 - 30s - loss: 0.0265 - acc: 0.9924 - val_loss: 0.2228 - val_acc: 0.9636\n",
            "Epoch 10/100\n",
            "100/100 - 29s - loss: 0.0216 - acc: 0.9939 - val_loss: 0.1383 - val_acc: 0.9838\n",
            "Epoch 11/100\n",
            "100/100 - 29s - loss: 0.0218 - acc: 0.9924 - val_loss: 0.1095 - val_acc: 0.9838\n",
            "Epoch 12/100\n",
            "100/100 - 29s - loss: 0.0190 - acc: 0.9954 - val_loss: 0.2731 - val_acc: 0.9676\n",
            "Epoch 13/100\n",
            "100/100 - 29s - loss: 0.0269 - acc: 0.9934 - val_loss: 0.3806 - val_acc: 0.9565\n",
            "Epoch 14/100\n",
            "100/100 - 28s - loss: 0.0146 - acc: 0.9965 - val_loss: 0.3878 - val_acc: 0.9585\n",
            "Epoch 15/100\n",
            "100/100 - 30s - loss: 0.0314 - acc: 0.9924 - val_loss: 0.2453 - val_acc: 0.9717\n",
            "Epoch 16/100\n",
            "100/100 - 30s - loss: 0.0221 - acc: 0.9944 - val_loss: 0.4880 - val_acc: 0.9585\n",
            "Epoch 17/100\n",
            "100/100 - 29s - loss: 0.0063 - acc: 0.9980 - val_loss: 0.4749 - val_acc: 0.9605\n",
            "Epoch 18/100\n",
            "100/100 - 29s - loss: 0.0391 - acc: 0.9939 - val_loss: 1.0890 - val_acc: 0.9403\n",
            "Epoch 19/100\n",
            "100/100 - 29s - loss: 0.0211 - acc: 0.9949 - val_loss: 1.0439 - val_acc: 0.9403\n",
            "Epoch 20/100\n",
            "100/100 - 29s - loss: 0.0356 - acc: 0.9894 - val_loss: 0.6492 - val_acc: 0.9464\n",
            "Epoch 21/100\n",
            "100/100 - 29s - loss: 0.0161 - acc: 0.9949 - val_loss: 1.1194 - val_acc: 0.9403\n",
            "Epoch 22/100\n",
            "100/100 - 29s - loss: 0.0216 - acc: 0.9935 - val_loss: 0.9552 - val_acc: 0.9403\n",
            "Epoch 23/100\n",
            "100/100 - 29s - loss: 0.0243 - acc: 0.9939 - val_loss: 1.5830 - val_acc: 0.9211\n",
            "Epoch 24/100\n",
            "100/100 - 30s - loss: 0.0193 - acc: 0.9954 - val_loss: 0.8254 - val_acc: 0.9453\n",
            "Epoch 25/100\n",
            "100/100 - 29s - loss: 0.0078 - acc: 0.9965 - val_loss: 0.5449 - val_acc: 0.9555\n",
            "Epoch 26/100\n",
            "100/100 - 29s - loss: 0.0242 - acc: 0.9949 - val_loss: 0.9148 - val_acc: 0.9484\n",
            "Epoch 27/100\n",
            "100/100 - 28s - loss: 0.0254 - acc: 0.9939 - val_loss: 0.7323 - val_acc: 0.9545\n",
            "Epoch 28/100\n",
            "100/100 - 30s - loss: 0.0277 - acc: 0.9939 - val_loss: 0.9622 - val_acc: 0.9504\n",
            "Epoch 29/100\n",
            "100/100 - 30s - loss: 0.0246 - acc: 0.9940 - val_loss: 1.2150 - val_acc: 0.9423\n",
            "Epoch 30/100\n",
            "100/100 - 29s - loss: 0.0296 - acc: 0.9939 - val_loss: 1.2483 - val_acc: 0.9383\n",
            "Epoch 31/100\n",
            "100/100 - 29s - loss: 0.0194 - acc: 0.9930 - val_loss: 0.7199 - val_acc: 0.9524\n",
            "Epoch 32/100\n",
            "100/100 - 29s - loss: 0.0247 - acc: 0.9939 - val_loss: 1.1551 - val_acc: 0.9332\n",
            "Epoch 33/100\n",
            "100/100 - 29s - loss: 0.0089 - acc: 0.9970 - val_loss: 0.6254 - val_acc: 0.9555\n",
            "Epoch 34/100\n",
            "100/100 - 29s - loss: 0.0145 - acc: 0.9960 - val_loss: 1.2462 - val_acc: 0.9372\n",
            "Epoch 35/100\n",
            "100/100 - 29s - loss: 0.0236 - acc: 0.9970 - val_loss: 0.6843 - val_acc: 0.9545\n",
            "Epoch 36/100\n",
            "100/100 - 29s - loss: 0.0199 - acc: 0.9954 - val_loss: 0.6532 - val_acc: 0.9524\n",
            "Epoch 37/100\n",
            "100/100 - 29s - loss: 0.0305 - acc: 0.9949 - val_loss: 1.1442 - val_acc: 0.9423\n",
            "Epoch 38/100\n",
            "100/100 - 29s - loss: 0.0326 - acc: 0.9929 - val_loss: 1.1704 - val_acc: 0.9403\n",
            "Epoch 39/100\n",
            "100/100 - 29s - loss: 0.0392 - acc: 0.9924 - val_loss: 0.9517 - val_acc: 0.9504\n",
            "Epoch 40/100\n",
            "100/100 - 28s - loss: 0.0407 - acc: 0.9939 - val_loss: 0.7574 - val_acc: 0.9474\n",
            "Epoch 41/100\n",
            "100/100 - 30s - loss: 0.0336 - acc: 0.9919 - val_loss: 0.4011 - val_acc: 0.9696\n",
            "Epoch 42/100\n",
            "100/100 - 30s - loss: 0.0148 - acc: 0.9955 - val_loss: 0.8064 - val_acc: 0.9443\n",
            "Epoch 43/100\n",
            "100/100 - 29s - loss: 0.0182 - acc: 0.9944 - val_loss: 1.1626 - val_acc: 0.9433\n",
            "Epoch 44/100\n",
            "100/100 - 29s - loss: 0.0089 - acc: 0.9975 - val_loss: 1.0030 - val_acc: 0.9423\n",
            "Epoch 45/100\n",
            "100/100 - 29s - loss: 0.0282 - acc: 0.9965 - val_loss: 1.2501 - val_acc: 0.9372\n",
            "Epoch 46/100\n",
            "100/100 - 29s - loss: 0.0107 - acc: 0.9975 - val_loss: 1.3110 - val_acc: 0.9393\n",
            "Epoch 47/100\n",
            "100/100 - 30s - loss: 0.0204 - acc: 0.9959 - val_loss: 0.8269 - val_acc: 0.9484\n",
            "Epoch 48/100\n",
            "100/100 - 29s - loss: 0.0086 - acc: 0.9965 - val_loss: 1.1373 - val_acc: 0.9413\n",
            "Epoch 49/100\n",
            "100/100 - 29s - loss: 0.0222 - acc: 0.9959 - val_loss: 1.4627 - val_acc: 0.9372\n",
            "Epoch 50/100\n",
            "100/100 - 29s - loss: 0.0070 - acc: 0.9980 - val_loss: 0.7924 - val_acc: 0.9484\n",
            "Epoch 51/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 29s - loss: 0.0023 - acc: 0.9995 - val_loss: 1.0400 - val_acc: 0.9443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "12fc4f92-bf62-455d-8767-10f660adb27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhxBCg/wC4KKnHg7dyvsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idvYWLNxppW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}